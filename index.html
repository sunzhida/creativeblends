<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta content="Creative Blends of Visual Concepts"
          name="description">
    <meta content="Creative Blends, Visual Concepts" name="keywords">
    <meta content="width=device-width, initial-scale=1" name="viewport">
    <title>Creative Blends of Visual Concepts</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-J23Z26SBHV"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-J23Z26SBHV');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Noto+Sans|Roboto"
          rel="stylesheet">

    <link href="./static/css/bootstrap.min.css" rel="stylesheet">
    <link href="./static/css/academicons.min.css" rel="stylesheet"/>
    <link href="./static/assets/fontawesome/css/all.min.css" rel="stylesheet">
    <link href="./static/css/main.css" rel="stylesheet">
    <link href="./static/images/favicon.ico" rel="icon">

    <script src="./static/js/bootstrap.min.js"></script>

</head>
<body>


<div class="container">
    <header class="sticky-top">
        <div class="d-flex flex-column flex-md-row align-items-center mb-4 border-bottom">
            <a class="d-flex align-items-center link-body-emphasis text-decoration-none"
               href="https://zhdsun.github.io/">
                <span class="text-center py-3 mt-2 mt-md-0 ms-md-auto fs-4"><i class="fa-solid fa-house"></i></span>
            </a>
            <nav class="d-inline-flex mt-2 mt-md-0 ms-md-auto">
                <a class="me-3 py-2 link-body-emphasis text-decoration-none" href="#">About</a>
                <a class="me-3 py-2 link-body-emphasis text-decoration-none" href="#abstract">Abstract</a>
                <a class="me-3 py-2 link-body-emphasis text-decoration-none" href="#content">Content</a>
                <a class="me-3 py-2 link-body-emphasis text-decoration-none" href="#cite">Cite</a>
            </nav>
        </div>
    </header>

    <div class="row">
        <section class="py-5 text-center container">
            <div class="row py-lg-5">
                <div class="col-lg-8 col-md-10 mx-auto">
                    <h3 class="">Creative Blends of Visual Concepts</h3>
                    <div class="publication-authors">
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://zhdsun.github.io/">Zhida Sun</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://ZhenyaoZhang.github.io/">Zhenyao Zhang</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://yuezhang-edward.github.io/">Yue Zhang</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://deardeer.github.io/">Min Lu</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://www.cs.huji.ac.il/~danix/">Dani Lischinski</a><sup>2</sup>,</span>
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://danielcohenor.com/">Daniel Cohen-Or</a><sup>3</sup>,</span>
                        <span class="author-block">
                            <a class="link-body-emphasis link-offset-2 link-underline-opacity-25 link-underline-opacity-75-hover"
                               href="https://www.cse.ust.hk/~mxj/">Xiaojuan Ma</a><sup>1</sup>.</span>
                    </div>
                    <div class="publication-authors">
                        <span class="author-block"><sup>1</sup>Shenzhen University,</span>
                        <span class="author-block"><sup>2</sup>The Hebrew University of Jerusalem,</span>
                        <span class="author-block"><sup>3</sup>Tel-Aviv University.</span>
                    </div>
                    <p>
                        <a class="btn btn-outline-dark rounded-pill my-2"
                           href="https://www.sciencedirect.com/science/article/pii/S1071581920300343">
                            <span class="icon">
                                    <i class="ai ai-acmdl"></i>
                                </span>
                            <span>Paper</span></a>
                        <a class="btn btn-outline-dark rounded-pill my-2"
                           href="https://arxiv.org/abs/2502.16062">
                            <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                </span>
                            <span>arXiv</span></a>
                        <a class="btn btn-outline-dark rounded-pill my-2"
                           href="https://vcc.szu.edu.cn/research/2025/CreativeBlends">
                            <span class="icon">
                                    <i class="fa-solid fa-bullhorn"></i>
                                </span>
                            <span>Media Coverage</span></a>
                    </p>
                </div>
            </div>
        </section>

        <section class="py-5 container">
            <div class="row">
                <div class="col-lg-8 col-md-10 mx-auto">
                    <div class="thumbnail">
                        <img alt="ijhcs_20_teaser" class="img-fluid img-thumbnail"
                             src="./static/images/teaser.jpg">
                        <div class="figure-caption">
                            <p>The Creative Blends system leverages textual user input to generate visual blends,
                                offering a platform for creative exploration. The system broadens the spectrum of design
                                possibilities by mapping abstract concepts – highlighted in blue and orange colors –
                                onto tangible physical objects through constructed metaphorical associations. These
                                mapped objects are then seamlessly integrated based on shared attributes, resulting in
                                conceptually meaningful and visually cohesive blends.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>


        <section class="py-5 container scmargin" id="abstract">
            <div class="row">
                <div class="p-4 p-md-5 mb-4 rounded text-body-emphasis bg-body-tertiary">
                    <div class="px-0">
                        <h4 class="text-center">Abstract</h4>
                        <p>
                            Visual blends combine elements from two distinct visual concepts into a single, integrated
                            image, with the goal of conveying ideas through imaginative and often thought-provoking
                            visuals. Communicating abstract concepts through visual blends poses a series of conceptual
                            and technical challenges. To address these challenges, we introduce Creative Blends, an
                            AI-assisted design system that leverages metaphors to visually symbolize abstract concepts
                            by blending disparate objects. Our method harnesses commonsense knowledge bases and large
                            language models to align designers’ conceptual intent with expressive concrete objects.
                            Additionally, we employ generative text-to-image techniques to blend visual elements through
                            their overlapping attributes. A user study (N=24) demonstrated that our approach reduces
                            participants’ cognitive load, fosters creativity, and enhances the metaphorical richness of
                            visual blend ideation. We explore the potential of our method to expand visual blends to
                            include multiple object blending and discuss the insights gained from designing with
                            generative AI.
                        </p>
                    </div>
                </div>
            </div>
        </section>


        <section class="py-5 container scmargin" id="content">
            <div class="row">
                <div class="py-5 col-lg-6 col-md-8 mx-auto">
                    <!--                    <h4>Research Questions</h4>-->
                    <!--                    <div class="py-4">-->
                    <!--                        <p><strong>RQ</strong>:  How to augment <strong>creative ideation</strong> through the generation of <strong>metaphorical</strong> visual blends.</p>-->
                    <!--                        -->
                    <!--                    </div>-->

                    <!--           -->
                    <!--                    <hr>-->


                    <h4>The Creative Blends pipeline</h4>


                    <div class="py-4 thumbnail">

                        <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                             src="./static/images/figure2.jpg">

                        <div class="figure-caption">
                            <p>Creative Blends operates through a multi-stage pipeline. The initial stage involves
                                concept inference to identify relevant objects and their attributes. Subsequently, a
                                similarity-based selection process empowers users to choose suitable object and
                                attribute combinations. The system then explores potential blending schemes and
                                synthesizes corresponding prompts for the T2I model, culminating in iterative image
                                generation based on the selected prompts to support the ideation process.

                            </p>
                        </div>
                    </div>
                    <hr>
                    <h4>The Creative Blends system </h4>
                    <div class="py-4">
                        <p>Creative Blends utilizes interactive visualizations to enable user exploration of generated
                            visual blends. The system's interface is organized into four modules: expression input,
                            prompt exploration, visual blend exploration, and similarity visualization.</p>

                        <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                             src="./static/images/figure3.jpg">
                        <div class="figure-caption">
                            <p>The user interface of Creative Blends showcases an example of generated results for
                                “global warming”. The interface consists of four distinct modules: the expression input
                                module (a), the prompt exploration module (b, c, d), the visual blend exploration module
                                (e), and the similarity visualization module (f).

                            </p>
                        </div>

                        <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                             src="./static/images/figure4.jpg">
                        <div class="figure-caption">
                            <p>The scheme generation prompt is structured into five distinct modules: system setup, task
                                definition, user input, a step-by-step execution process, and a results format
                                demonstration.</p>

                            </p>
                        </div>

                        <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                             src="./static/images/figure5.jpg">
                        <div class="figure-caption">
                            <p>The resulting schemes are then utilized to construct a final prompt for the DALL·E 3
                                model. This final prompt incorporates objects, attributes, schemes, and contextual
                                considerations, with the schemes and metaphorical themes dynamically generated by
                                GPT.</p>

                            </p>
                        </div>


                    </div>
                    <hr>
                    <h4>Evaluation Methods</h4>
                    <div class="py-4 thumbnail">
                        <img alt="ijhcs_20_detail" class="img-responsive img-thumbnail col-md-12"
                             src="./static/images/figure6.jpg">
                        <div class="figure-caption">
                            <p>A within-subjects study with 24 participants was conducted to evaluate Creative Blends
                                against a baseline comprising ChatGPT and Google Search.

                            </p>
                        </div>
                    </div>
                    <hr>
                    <h4>Results</h4>
                    <div class="py-4">
                        <p>User ratings were collected across five dimensions: <i>Usability</i>, <i>Cognitive Load</i>,
                            <i>Outcome Satisfaction</i>, <i>Creativity</i>, and <i>Metaphoricity</i>. Statistical
                            analysis of these ratings revealed that Creative Blends significantly outperformed the
                            baseline in <i><strong>Creativity</strong></i>, <i><strong>Metaphoricity</strong></i>, and
                            overall <i><strong>user experience</strong></i>, demonstrating its efficacy in generating
                            visually compelling ideas for abstract concepts.</p>

                        <div class="text-center">
                            <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                                 src="./static/images/Figure17.png">
                            <div class="figure-caption text-start">
                                <p>The statistical results of user feedback with the Creative Blends and the baseline.
                                </p>
                            </div>
                        </div>
                        <div class="text-center">
                            <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                                 src="./static/images/figure9.jpg">
                            <div class="figure-caption text-start">
                                <p> Creative Blends generates diverse visual blends representing abstract concepts based
                                    on user-provided expressions. Each topic includes eight examples: four highlighting
                                    different levels of object similarity and four demonstrating varying attribute
                                    similarity. Similarity increases from left to right. The attributes are extended
                                    based on the objects enclosed by the double brackets. Colors within the topics serve
                                    to identify concepts and their associated objects and attributes.

                                </p>
                            </div>
                        </div>
                        <div class="text-center">
                            <img alt="ijhcs_20_detail" class="img-fluid img-thumbnail col-md-12"
                                 src="./static/images/figure15.jpg">
                            <div class="figure-caption text-start">
                                <p> The Sample ideas generated by Creative Blends. These examples are randomly selected
                                    from the topics used in previous research or commonly used in our daily lives.
                                </p>
                            </div>
                        </div>
                    </div>
                    <hr>
                    <h4>Reflection</h4>
                    <div class="py-4">
                        <p>In summary, this research proposes a novel <i><strong>metaphor-based</strong></i> visual
                            blending approach , leveraging commonsense reasoning to identify semantically relevant
                            objects and subsequently synthesize them based on attribute similarity. We present
                            <i><strong>Creative Blends</strong></i>, an AI-assisted system designed to enhance creative
                            ideation in visual blending through the use of metaphors. Through a comprehensive
                            evaluation, we demonstrate how metaphors can facilitate abstract concept design in
                            AIGC, enhancing creative workflows and visual ideation.</p>
                        </p>
                    </div>
                </div>
            </div>
        </section>
        <section class="py-5 container scmargin" id="cite">
            <div class="row">
                <div class="p-4 p-md-5 mb-4 rounded text-body-emphasis bg-body-tertiary">
                    <div class="px-0">
                        <h4 class="text-center">BibTeX</h4>
                        <pre><code>
                            @misc{sun2025creativeblendsvisualconcepts,
                                title={Creative Blends of Visual Concepts}, 
                                author={Zhida Sun and Zhenyao Zhang and Yue Zhang and Min Lu and Dani Lischinski and Daniel Cohen-Or and Hui Huang},
                                year={2025},
                                eprint={2502.16062},
                                archivePrefix={arXiv},
                                primaryClass={cs.HC},
                                url={https://arxiv.org/abs/2502.16062}, 
                          }
                        </code></pre>
                    </div>
                </div>
            </div>
        </section>
    </div>
</div>

<footer class="footer text-center opensans light">
    <div class="border-top py-3 mb-3">
        <small>Copyright © 2016 - Present &emsp; <img alt="Logo" src="./static/images/z.svg"> &emsp; Zhida Sun</small>
    </div>
    <p class="py-3"></p>
</footer>

</body>
</html>
